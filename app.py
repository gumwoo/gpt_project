import streamlit as st
import pandas as pd
import numpy as np
import json
import requests
import os
from io import StringIO
import matplotlib.pyplot as plt
import seaborn as sns
from prompts import generate_data_story_prompt
from data_loader import load_sample_data, get_sample_data_info, load_uploaded_file
from data_visualizer import create_chart, auto_generate_charts, set_matplotlib_korean_font

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì‹œë„ (ë¡œì»¬ ê°œë°œ í™˜ê²½ìš©)
try:
    import dotenv
    dotenv.load_dotenv()
except ImportError:
    pass

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë°ì´í„° ìŠ¤í† ë¦¬í…”ëŸ¬",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# API í‚¤ ì„¤ì • - Streamlit Cloudì˜ secrets ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œ
if 'OPENAI_API_KEY' in st.secrets:
    API_KEY = st.secrets['OPENAI_API_KEY']
else:
    API_KEY = os.getenv("OPENAI_API_KEY")

OPENAI_API_URL = "https://api.openai.com/v1/chat/completions"

# API í‚¤ê°€ ì—†ëŠ” ê²½ìš° ê²½ê³ 
if not API_KEY:
    st.warning("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Cloudì˜ secrets ë˜ëŠ” .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

# í•œê¸€ í°íŠ¸ ì„¤ì • ì‹œë„ (ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ì•±ì€ ê³„ì† ì‘ë™)
try:
    set_matplotlib_korean_font()
except Exception as e:
    st.warning(f"í•œê¸€ í°íŠ¸ ì„¤ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}. í•œê¸€ì´ ê¹¨ì ¸ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# GPT API í˜¸ì¶œ í•¨ìˆ˜
def generate_data_story(prompt, model="gpt-3.5-turbo"):
    if not API_KEY:
        st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
        
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_KEY}"
    }
    
    payload = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7
    }
    
    # response_format ì¶”ê°€ (ì¼ë¶€ ëª¨ë¸ë§Œ ì§€ì›)
    try:
        # ìµœì‹  ëª¨ë¸ì—ë§Œ ì ìš©
        if "gpt-4" in model or "-turbo" in model:
            payload["response_format"] = {"type": "json_object"}
    except:
        # ì˜¤ë¥˜ ë°œìƒì‹œ ë¬´ì‹œ
        pass
    
    try:
        response = requests.post(OPENAI_API_URL, headers=headers, json=payload)
        response.raise_for_status()  # ì˜¤ë¥˜ ë°œìƒì‹œ ì˜ˆì™¸ ë°œìƒ
        
        # ì‘ë‹µ ë””ë²„ê¹…
        st.write("API ì‘ë‹µ:", response.status_code)
        
        # ì‘ë‹µ í˜•ì‹ í™•ì¸
        response_json = response.json()
        if "choices" in response_json and len(response_json["choices"]) > 0:
            content = response_json["choices"][0]["message"]["content"]
            try:
                return json.loads(content)
            except json.JSONDecodeError:
                st.error("API ì‘ë‹µì´ ìœ íš¨í•œ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
                st.write("ì›ë³¸ ì‘ë‹µ:", content)
                return None
        else:
            st.error(f"API ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: {response_json}")
            return None
    except requests.exceptions.RequestException as e:
        st.error(f"API ìš”ì²­ ì˜¤ë¥˜: {e}")
        if hasattr(e, 'response') and e.response is not None:
            st.error(f"ì‘ë‹µ ë‚´ìš©: {e.response.text}")
        return None
    except (KeyError, json.JSONDecodeError) as e:
        st.error(f"ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None

# ê¸°ë³¸ í†µê³„ ë¶„ì„ í•¨ìˆ˜
def analyze_dataframe(df):
    analysis = {}
    
    # ê¸°ë³¸ ì •ë³´
    analysis["basic_info"] = {
        "rows": df.shape[0],
        "columns": df.shape[1],
        "column_types": {col: str(dtype) for col, dtype in df.dtypes.items()}
    }
    
    # ìˆ˜ì¹˜í˜• ì—´ì— ëŒ€í•œ ê¸°ë³¸ í†µê³„
    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
    if numeric_cols:
        analysis["numeric_stats"] = {}
        for col in numeric_cols:
            analysis["numeric_stats"][col] = {
                "mean": float(df[col].mean()),
                "median": float(df[col].median()),
                "min": float(df[col].min()),
                "max": float(df[col].max()),
                "std": float(df[col].std())
            }
        
        # ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤
        if len(numeric_cols) > 1:
            corr_matrix = df[numeric_cols].corr().to_dict()
            analysis["correlation"] = corr_matrix
    
    # ë²”ì£¼í˜• ì—´ì— ëŒ€í•œ ê¸°ë³¸ í†µê³„
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    if categorical_cols:
        analysis["categorical_stats"] = {}
        for col in categorical_cols:
            # ìƒìœ„ 5ê°œ ì¹´í…Œê³ ë¦¬ë§Œ í¬í•¨
            counts = df[col].value_counts().head(5).to_dict()
            analysis["categorical_stats"][col] = counts
    
    # ê²°ì¸¡ì¹˜ ì •ë³´
    analysis["missing_values"] = df.isnull().sum().to_dict()
    
    return analysis

# ì• í”Œë¦¬ì¼€ì´ì…˜ UI
def main():
    st.title("ğŸ“Š ë°ì´í„° ìŠ¤í† ë¦¬í…”ëŸ¬")
    st.markdown("#### ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê³  AIê°€ ë¶„ì„í•œ ìŠ¤í† ë¦¬ë¥¼ í™•ì¸í•˜ì„¸ìš”!")
    
    with st.sidebar:
        st.header("ì„¤ì •")
        audience = st.selectbox(
            "ëŒ€ìƒ ì²­ì¤‘",
            ["ê²½ì˜ì§„", "ë§ˆì¼€íŒ…íŒ€", "ê¸°ìˆ íŒ€", "ì¼ë°˜ ëŒ€ì¤‘"]
        )
        
        story_focus = st.selectbox(
            "ìŠ¤í† ë¦¬ ì¤‘ì ",
            ["ì£¼ìš” íŠ¸ë Œë“œ", "ì´ìƒì¹˜ ë° íŠ¹ì´ì ", "ìƒê´€ê´€ê³„ ë¶„ì„", "ì¢…í•© ì¸ì‚¬ì´íŠ¸"]
        )
        
        story_length = st.select_slider(
            "ìŠ¤í† ë¦¬ ê¸¸ì´",
            options=["ê°„ê²°", "ë³´í†µ", "ìƒì„¸"],
            value="ë³´í†µ"
        )
        
        # matplotlib ìŠ¤íƒ€ì¼ ëª©ë¡ ìˆ˜ì • - ìµœì‹  ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•´
        available_styles = ['default', 'classic', 'ggplot', 'bmh', 'dark_background']
        
        chart_style = st.selectbox(
            "ì°¨íŠ¸ ìŠ¤íƒ€ì¼",
            available_styles
        )
        
        # ìŠ¤íƒ€ì¼ ì ìš© ì‹œë„, ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ ìŠ¤íƒ€ì¼ ì‚¬ìš©
        try:
            plt.style.use(chart_style)
        except Exception as e:
            st.warning(f"ìŠ¤íƒ€ì¼ '{chart_style}'ì„ ì ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ìŠ¤íƒ€ì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            plt.style.use('default')
    
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['csv'])
    
    df = None
    
    if uploaded_file is not None:
        try:
            # ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬
            try:
                # ë¨¼ì € ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ ì‹œë„
                df = pd.read_csv(uploaded_file)
            except UnicodeDecodeError:
                # ì¸ì½”ë”© ì˜¤ë¥˜ ë°œìƒ ì‹œ ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ ì‚¬ìš©
                uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ì´ˆê¸°í™”
                df = load_uploaded_file(uploaded_file)
            
            # ê¸°ë³¸ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
            st.subheader("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
            st.dataframe(df.head())
            
            # ê¸°ë³¸ ì •ë³´ í‘œì‹œ
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("í–‰ ìˆ˜", df.shape[0])
            with col2:
                st.metric("ì—´ ìˆ˜", df.shape[1])
            with col3:
                st.metric("ê²°ì¸¡ì¹˜", df.isnull().sum().sum())
            
        except Exception as e:
            st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    else:
        # ìƒ˜í”Œ ë°ì´í„° ì˜µì…˜
        st.markdown("### ë˜ëŠ” ìƒ˜í”Œ ë°ì´í„°ë¡œ ì‹œì‘í•˜ì„¸ìš”")
        sample_data_info = get_sample_data_info()
        sample_options = ["ì„ íƒí•˜ì„¸ìš”..."] + [info["title"] for info in sample_data_info.values()]
        
        sample_option = st.selectbox(
            "ìƒ˜í”Œ ë°ì´í„° ì„ íƒ",
            sample_options
        )
        
        if sample_option != "ì„ íƒí•˜ì„¸ìš”...":
            # ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ
            sample_name = next((name for name, info in sample_data_info.items() 
                              if info["title"] == sample_option), None)
            if sample_name:
                try:
                    df = load_sample_data(sample_name)
                    
                    # ê¸°ë³¸ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                    st.subheader("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
                    st.dataframe(df.head())
                    
                    # ê¸°ë³¸ ì •ë³´ í‘œì‹œ
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("í–‰ ìˆ˜", df.shape[0])
                    with col2:
                        st.metric("ì—´ ìˆ˜", df.shape[1])
                    with col3:
                        st.metric("ê²°ì¸¡ì¹˜", df.isnull().sum().sum())
                    
                    st.success(f"{sample_option} ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. 'ë°ì´í„° ìŠ¤í† ë¦¬ ìƒì„±' ë²„íŠ¼ì„ ëˆŒëŸ¬ ê³„ì†í•˜ì„¸ìš”.")
                except Exception as e:
                    st.error(f"ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # ë°ì´í„° ë¶„ì„ ë²„íŠ¼
    if df is not None and st.button("ë°ì´í„° ìŠ¤í† ë¦¬ ìƒì„±"):
        with st.spinner("ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìŠ¤í† ë¦¬ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            # ë°ì´í„° ë¶„ì„
            analysis_result = analyze_dataframe(df)
            
            # ë¶„ì„ ê²°ê³¼ ë””ë²„ê¹… (ê°œë°œ ì¤‘ì—ë§Œ ì‚¬ìš©)
            with st.expander("ë°ì´í„° ë¶„ì„ ê²°ê³¼ (ë””ë²„ê¹…ìš©)"):
                st.json(analysis_result)
            
            # ì‚¬ìš©ì ì„¤ì •ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = generate_data_story_prompt(
                dataframe_info=analysis_result,
                audience=audience,
                focus=story_focus,
                length=story_length,
                sample_data=df.head(10).to_dict()
            )
            
            # í”„ë¡¬í”„íŠ¸ ë””ë²„ê¹… (ê°œë°œ ì¤‘ì—ë§Œ ì‚¬ìš©)
            with st.expander("ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ (ë””ë²„ê¹…ìš©)"):
                st.text(prompt)
            
            # GPT API í˜¸ì¶œ ì „ ë”ë¯¸ ë°ì´í„° ì¤€ë¹„ (API ì˜¤ë¥˜ ì‹œ ì‚¬ìš©)
            dummy_data = {
                "key_insights": [
                    {
                        "title": "ìƒ˜í”Œ ì¸ì‚¬ì´íŠ¸ 1",
                        "description": "ì´ê²ƒì€ API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ í‘œì‹œë˜ëŠ” ìƒ˜í”Œ ì¸ì‚¬ì´íŠ¸ì…ë‹ˆë‹¤.",
                        "chart_recommendation": {
                            "type": "bar",
                            "x_column": df.columns[0] if len(df.columns) > 0 else "",
                            "y_column": df.select_dtypes(include=['int64', 'float64']).columns[0] if len(df.select_dtypes(include=['int64', 'float64']).columns) > 0 else "",
                            "title": "ìƒ˜í”Œ ì°¨íŠ¸",
                            "description": "ìƒ˜í”Œ ì°¨íŠ¸ ì„¤ëª…"
                        }
                    }
                ],
                "narrative": "ì´ê²ƒì€ API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ í‘œì‹œë˜ëŠ” ìƒ˜í”Œ ë‚´ëŸ¬í‹°ë¸Œì…ë‹ˆë‹¤. ì‹¤ì œ APIê°€ ì„±ê³µì ìœ¼ë¡œ í˜¸ì¶œë˜ë©´ ì´ í…ìŠ¤íŠ¸ëŠ” ëŒ€ì²´ë©ë‹ˆë‹¤.",
                "recommended_actions": [
                    {
                        "title": "ìƒ˜í”Œ ì•¡ì…˜",
                        "description": "ì´ê²ƒì€ ìƒ˜í”Œ ì¶”ì²œ ì•¡ì…˜ì…ë‹ˆë‹¤."
                    }
                ]
            }
            
            # GPT API í˜¸ì¶œ
            story_result = generate_data_story(prompt)
            
            # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ë”ë¯¸ ë°ì´í„° ì‚¬ìš©
            if story_result is None:
                st.warning("GPT API í˜¸ì¶œì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìƒ˜í”Œ ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")
                story_result = dummy_data
            
            # ê²°ê³¼ í‘œì‹œ
            st.subheader("ğŸ“ ë°ì´í„° ìŠ¤í† ë¦¬")
            
            # ì£¼ìš” ì¸ì‚¬ì´íŠ¸ í‘œì‹œ
            st.markdown("### ì£¼ìš” ì¸ì‚¬ì´íŠ¸")
            
            if "key_insights" in story_result and isinstance(story_result["key_insights"], list):
                for i, insight in enumerate(story_result["key_insights"]):
                    if not isinstance(insight, dict):
                        continue
                        
                    title = insight.get("title", f"ì¸ì‚¬ì´íŠ¸ {i+1}")
                    with st.expander(f"ì¸ì‚¬ì´íŠ¸ {i+1}: {title}"):
                        st.markdown(insight.get("description", ""))
                        
                        # ì°¨íŠ¸ ì¶”ì²œì´ ìˆëŠ” ê²½ìš°
                        if "chart_recommendation" in insight and isinstance(insight["chart_recommendation"], dict):
                            chart_info = insight["chart_recommendation"]
                            st.markdown(f"**ì¶”ì²œ ì°¨íŠ¸**: {chart_info.get('type', '')}")
                            
                            # ì°¨íŠ¸ ìƒì„± ì‹œë„
                            try:
                                if all(k in chart_info for k in ["type", "x_column", "y_column"]):
                                    if chart_info["x_column"] in df.columns and chart_info["y_column"] in df.columns:
                                        fig = create_chart(df, chart_info)
                                        if fig:
                                            st.pyplot(fig)
                                        else:
                                            st.warning("ì°¨íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                    else:
                                        st.warning(f"ì°¨íŠ¸ ìƒì„±ì— í•„ìš”í•œ ì—´({chart_info['x_column']} ë˜ëŠ” {chart_info['y_column']})ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
                            except Exception as e:
                                st.error(f"ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            else:
                st.warning("ì¸ì‚¬ì´íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # ì¢…í•© ìŠ¤í† ë¦¬ í‘œì‹œ
            st.markdown("### ì¢…í•© ë°ì´í„° ìŠ¤í† ë¦¬")
            st.markdown(story_result.get("narrative", "ë‚´ëŸ¬í‹°ë¸Œ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."))
            
            # ì¶”ì²œ ì•¡ì…˜ í‘œì‹œ
            if "recommended_actions" in story_result and isinstance(story_result["recommended_actions"], list):
                st.markdown("### ì¶”ì²œ ì•¡ì…˜")
                for action in story_result["recommended_actions"]:
                    if isinstance(action, dict):
                        st.markdown(f"- **{action.get('title', '')}**: {action.get('description', '')}")
            
            # ì›ë³¸ JSON ë°ì´í„° ë³´ê¸° (ë””ë²„ê¹…ìš©)
            with st.expander("ì›ë³¸ JSON ë°ì´í„°"):
                st.json(story_result)
    
    # í•„ìˆ˜ íŒ¨í‚¤ì§€ ì •ë³´
    with st.expander("í•„ìš”í•œ íŒ¨í‚¤ì§€ ì •ë³´"):
        st.markdown("""
        ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•´ í•„ìš”í•œ Python íŒ¨í‚¤ì§€:
        - streamlit
        - pandas
        - numpy
        - matplotlib
        - seaborn
        - requests
        - chardet (í•œê¸€ ì¸ì½”ë”© ê°ì§€ìš©)
        
        ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œ ì‹¤í–‰í•  ê²½ìš°:
        - python-dotenv (í™˜ê²½ ë³€ìˆ˜ ë¡œë“œìš©)
        
        API í‚¤ ì„¤ì • ë°©ë²•:
        - Streamlit Cloudì—ì„œëŠ” ì•± ì„¤ì •ì˜ Secrets ë©”ë‰´ì—ì„œ OPENAI_API_KEY ì„¤ì •
        - ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œëŠ” .env íŒŒì¼ì— OPENAI_API_KEY=your_api_key_here ì¶”ê°€
        """)
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown("ë°ì´í„° ìŠ¤í† ë¦¬í…”ëŸ¬ | GPT API ê¸°ë°˜ ë°ì´í„° ë¶„ì„ ë° ìŠ¤í† ë¦¬í…”ë§ ë„êµ¬")

if __name__ == "__main__":
    main()
